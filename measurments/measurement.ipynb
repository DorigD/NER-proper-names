{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for dataset_name = a.conll:\n",
      "               model_version dataset_name  dataset_size   model_size  execution_time  load_time  B-PER_precision  B-PER_recall  B-PER_f1\n",
      "0    version-12-roberta-base      a.conll           424  124058116.0        2.308745   1.046717         0.966480      0.988571  0.977401\n",
      "117  version-21-roberta-base      a.conll           424  124058116.0        1.784312   0.867127         0.513208      0.777143  0.618182\n",
      "78   version-18-roberta-base      a.conll           424  124058116.0        1.765042   0.867784         0.573883      0.954286  0.716738\n",
      "130  version-22-roberta-base      a.conll           424  124058116.0        1.744143   0.867132         0.601732      0.794286  0.684729\n",
      "65   version-17-roberta-base      a.conll           424  124058116.0        1.822620   0.856325         0.613281      0.897143  0.728538\n",
      "91   version-19-roberta-base      a.conll           424  124058116.0        1.735161   0.856766         0.728324      0.720000  0.724138\n",
      "13   version-13-roberta-base      a.conll           424  124058116.0        1.919781   0.858095         0.685950      0.948571  0.796163\n",
      "52   version-16-roberta-base      a.conll           424  124058116.0        1.765837   0.871068         0.611940      0.937143  0.740406\n",
      "143  version-23-roberta-base      a.conll           424  124058116.0        1.765858   0.851181         0.591093      0.834286  0.691943\n",
      "39   version-15-roberta-base      a.conll           424  124058116.0        1.690088   0.902118         0.587591      0.920000  0.717149\n",
      "26   version-14-roberta-base      a.conll           424  124058116.0        1.712322   0.878254         0.636719      0.931429  0.756381\n",
      "104  version-20-roberta-base      a.conll           424  124058116.0        1.869215   0.866258         0.487973      0.811429  0.609442\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "notebook_dir = os.getcwd()\n",
    "sys.path.append(os.path.abspath(os.path.join(notebook_dir, '..')))\n",
    "from utils.config import PROJECT_DIR\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "csv_folder = os.path.join(PROJECT_DIR, \"evaluation_results\")\n",
    "no_title_file = os.path.join(csv_folder, \"model_evaluations_no_title.csv\")\n",
    "title_file = os.path.join(csv_folder, \"model_evaluations.csv\")\n",
    "df_nt = pd.read_csv(title_file)\n",
    "def clear_evaluation_metrics(df):\n",
    "    \"\"\"\n",
    "    Remove overall_f1, overall_recall, and overall_precision columns from the DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing the evaluation metrics\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with metrics columns removed\n",
    "    \"\"\"\n",
    "    columns_to_remove = ['overall_f1', 'overall_recall', 'overall_precision', \"error\", 'I-PER_precision', 'I-PER_recall', 'I-PER_f1']\n",
    "    \n",
    "    # Drop columns that exist in the DataFrame\n",
    "    existing_columns = [col for col in columns_to_remove if col in df.columns]\n",
    "    if existing_columns:\n",
    "        df = df.drop(columns=existing_columns)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_nt_cleared = clear_evaluation_metrics(df_nt.copy())\n",
    "df_sorted = df_nt_cleared.sort_values(by=['dataset_name'])\n",
    "# Filter the DataFrame for dataset_name = a.conll\n",
    "df_aconll = df_sorted[df_sorted['dataset_name'] == 'a.conll']\n",
    "\n",
    "print(\"\\nResults for dataset_name = a.conll:\")\n",
    "print(df_aconll)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NER",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
